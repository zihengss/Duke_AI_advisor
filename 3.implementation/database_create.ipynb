{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735671849.438896 2231327 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1735671849.441627 2232201 subchannel.cc:806] subchannel 0x12c786b00 {address=unix:/var/folders/rn/5219x28n1bb9p3w3td_571000000gn/T/tmpblfh87b8_dukies.db.sock, args={grpc.client_channel_factory=0x11cafedc0, grpc.default_authority=var%2Ffolders%2Frn%2F5219x28n1bb9p3w3td_571000000gn%2FT%2Ftmpblfh87b8_dukies.db.sock, grpc.enable_retries=1, grpc.internal.channel_credentials=0x11caf3300, grpc.internal.client_channel_call_destination=0x12b9cba18, grpc.internal.event_engine=0x12d6112f0, grpc.internal.security_connector=0x12c722ca0, grpc.internal.subchannel_pool=0x12c56ab50, grpc.keepalive_time_ms=55000, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x11cabf180, grpc.server_uri=unix:/var/folders/rn/5219x28n1bb9p3w3td_571000000gn/T/tmpblfh87b8_dukies.db.sock}}: connect failed (UNKNOWN:connect: No such file or directory (2) {created_time:\"2024-12-31T14:04:09.441031-05:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1735671850.445165 2232194 subchannel.cc:761] subchannel 0x12c786b00 {address=unix:/var/folders/rn/5219x28n1bb9p3w3td_571000000gn/T/tmpblfh87b8_dukies.db.sock, args={grpc.client_channel_factory=0x11cafedc0, grpc.default_authority=var%2Ffolders%2Frn%2F5219x28n1bb9p3w3td_571000000gn%2FT%2Ftmpblfh87b8_dukies.db.sock, grpc.enable_retries=1, grpc.internal.channel_credentials=0x11caf3300, grpc.internal.client_channel_call_destination=0x12b9cba18, grpc.internal.event_engine=0x12d6112f0, grpc.internal.security_connector=0x12c722ca0, grpc.internal.subchannel_pool=0x12c56ab50, grpc.keepalive_time_ms=55000, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x11cabf180, grpc.server_uri=unix:/var/folders/rn/5219x28n1bb9p3w3td_571000000gn/T/tmpblfh87b8_dukies.db.sock}}: backoff delay elapsed, reporting IDLE\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"dukies.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'rag_collection'\n",
    "if client.has_collection(collection_name=collection_name):\n",
    "    client.drop_collection(collection_name=collection_name)\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=768,  # The vectors we will use in this demo has 768 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihengs/myenv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735671864.369341 2231327 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 33 entities, each with fields:  dict_keys(['id', 'vector', 'text', 'subject'])\n",
      "Vector dim: 768\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import os\n",
    "\n",
    "model_path = '../models/gte-base-en-v1.5'\n",
    "model = SentenceTransformer(model_path, trust_remote_code=True)\n",
    "\n",
    "# Path to the directory containing text files\n",
    "directory_path = '/Users/zihengs/Desktop/Duke_AI_advisor/data/rag_data/cs_professor'\n",
    "\n",
    "def remove_empty_lines(input_string):\n",
    "    return '\\n'.join(line for line in input_string.splitlines() if line.strip())\n",
    "\n",
    "# Initialize an empty list to store the contents of the text files\n",
    "docs = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and read the contents of the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            docs.append(remove_empty_lines(file.read()))\n",
    "\n",
    "# Print the loaded documents (optional)\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "\n",
    "\n",
    "vectors = model.encode(docs)\n",
    "\n",
    "data = [\n",
    "    {\"id\": i, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"professor\"}\n",
    "    for i in range(len(vectors))\n",
    "]\n",
    "\n",
    "print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_count': 33, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]}\n"
     ]
    }
   ],
   "source": [
    "res = client.insert(collection_name=collection_name, data=data)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 65 documents.\n",
      "Data has 65 entities, each with fields:  dict_keys(['id', 'vector', 'text', 'subject'])\n",
      "Vector dim: 768\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import os\n",
    "\n",
    "model_path = '../models/gte-base-en-v1.5'\n",
    "model = SentenceTransformer(model_path, trust_remote_code=True)\n",
    "\n",
    "# Path to the directory containing text files\n",
    "directory_path = '/Users/zihengs/Desktop/Duke_AI_advisor/data/rag_data/ece_professor'\n",
    "\n",
    "# Initialize an empty list to store the contents of the text files\n",
    "docs = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and read the contents of the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            docs.append(remove_empty_lines(file.read()))\n",
    "\n",
    "# Print the loaded documents (optional)\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "\n",
    "\n",
    "vectors = model.encode(docs)\n",
    "\n",
    "data = [\n",
    "    {\"id\": i+1000, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"professor\"}\n",
    "    for i in range(len(vectors))\n",
    "]\n",
    "\n",
    "print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_count': 65, 'ids': [1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064]}\n"
     ]
    }
   ],
   "source": [
    "res = client.insert(collection_name=collection_name, data=data)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 124 documents.\n",
      "Data has 124 entities, each with fields:  dict_keys(['id', 'vector', 'text', 'subject'])\n",
      "Vector dim: 768\n",
      "{'insert_count': 124, 'ids': [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123]}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import os\n",
    "\n",
    "model_path = '../models/gte-base-en-v1.5'\n",
    "model = SentenceTransformer(model_path, trust_remote_code=True)\n",
    "\n",
    "# Path to the directory containing text files\n",
    "directory_path = '/Users/zihengs/Desktop/Duke_AI_advisor/data/rag_data/cs_courses'\n",
    "\n",
    "# Initialize an empty list to store the contents of the text files\n",
    "docs = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and read the contents of the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            docs.append(remove_empty_lines(file.read()))\n",
    "\n",
    "# Print the loaded documents (optional)\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "\n",
    "\n",
    "vectors = model.encode(docs)\n",
    "\n",
    "data = [\n",
    "    {\"id\": i+2000, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"courses\"}\n",
    "    for i in range(len(vectors))\n",
    "]\n",
    "\n",
    "print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))\n",
    "\n",
    "res = client.insert(collection_name=collection_name, data=data)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 118 documents.\n",
      "Data has 118 entities, each with fields:  dict_keys(['id', 'vector', 'text', 'subject'])\n",
      "Vector dim: 768\n",
      "{'insert_count': 118, 'ids': [3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117]}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import os\n",
    "\n",
    "model_path = '../models/gte-base-en-v1.5'\n",
    "model = SentenceTransformer(model_path, trust_remote_code=True)\n",
    "\n",
    "# Path to the directory containing text files\n",
    "directory_path = '/Users/zihengs/Desktop/Duke_AI_advisor/data/rag_data/ece_courses'\n",
    "\n",
    "# Initialize an empty list to store the contents of the text files\n",
    "docs = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and read the contents of the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            docs.append(remove_empty_lines(file.read()))\n",
    "\n",
    "# Print the loaded documents (optional)\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "\n",
    "\n",
    "vectors = model.encode(docs)\n",
    "\n",
    "data = [\n",
    "    {\"id\": i+3000, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"courses\"}\n",
    "    for i in range(len(vectors))\n",
    "]\n",
    "\n",
    "print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))\n",
    "\n",
    "res = client.insert(collection_name=collection_name, data=data)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
